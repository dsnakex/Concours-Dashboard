# Automatisation du Scraping - Documentation

## ğŸ”„ SystÃ¨me de RÃ©cupÃ©ration Automatique

Le dashboard rÃ©cupÃ¨re automatiquement les nouveaux concours depuis des sites externes grÃ¢ce Ã  un systÃ¨me de scraping intelligent.

## âš™ï¸ Configuration Actuelle

### Cron Job Vercel
- **FrÃ©quence** : Tous les jours Ã  8h00 (heure UTC)
- **Endpoint** : `/api/admin/ingest`
- **Configuration** : `vercel.json` â†’ section `crons`

```json
{
  "crons": [{
    "path": "/api/admin/ingest",
    "schedule": "0 8 * * *"
  }]
}
```

### Format Cron
Le format est : `minute heure jour_mois mois jour_semaine`

Exemples :
- `0 8 * * *` - Tous les jours Ã  8h00
- `0 */6 * * *` - Toutes les 6 heures
- `0 8,20 * * *` - Ã€ 8h et 20h chaque jour
- `0 8 * * 1` - Tous les lundis Ã  8h

## ğŸ¤– Scrapers Disponibles

### 1. LesDemonsduJeu (`lesdemonsdujeu`)
- **URL** : https://www.lesdemonsdujeu.com/concours
- **Technologie** : Cheerio (parsing HTML robuste)
- **Rate Limit** : 2 secondes entre chaque requÃªte
- **Status** : âœ… ActivÃ©

#### FonctionnalitÃ©s
- âœ… DÃ©tection adaptative des sÃ©lecteurs CSS
- âœ… Extraction multi-approche (titre, lien, description, marque, date)
- âœ… Gestion des URLs relatives/absolues
- âœ… DÃ©tection automatique du type de participation
- âœ… Estimation de la valeur et du temps requis
- âœ… DÃ©doublonnage automatique

## ğŸ“Š Processus de Scraping

### Ã‰tape 1 : RÃ©cupÃ©ration
```
Cron Job (8h) â†’ API /api/admin/ingest â†’ scrapeAllSources()
```

### Ã‰tape 2 : Parsing Intelligent
```typescript
// Le scraper essaie plusieurs sÃ©lecteurs CSS
const selectors = [
  'article.contest',
  'article[class*="concours"]',
  'div.contest-item',
  // ... 8 sÃ©lecteurs au total
]

// Puis extrait les informations avec fallbacks multiples
```

### Ã‰tape 3 : Enrichissement
- Type de participation (direct, quiz, rÃ©seaux sociaux, etc.)
- CatÃ©gorie du lot (voyage, tech, argent, etc.)
- Temps estimÃ© selon la complexitÃ©
- Valeur estimÃ©e du lot
- DÃ©tection d'achat obligatoire

### Ã‰tape 4 : Insertion en Base
- VÃ©rification des doublons via `lien_source`
- Score initial Ã  0.5
- Statut "actif"
- Logging dans `ingest_logs`

## ğŸ” Monitoring

### VÃ©rifier les Logs d'Ingestion
```sql
SELECT * FROM ingest_logs
ORDER BY started_at DESC
LIMIT 10;
```

### Stats d'un Scraping
```sql
SELECT
  source,
  COUNT(*) as total_concours,
  MAX(created_at) as derniere_import
FROM concours
GROUP BY source;
```

## ğŸš€ DÃ©clencher Manuellement

### Via cURL
```bash
# Tous les scrapers
curl -X POST https://votre-site.vercel.app/api/admin/ingest

# Scraper spÃ©cifique
curl -X POST https://votre-site.vercel.app/api/admin/ingest \
  -H "Content-Type: application/json" \
  -d '{"source": "lesdemonsdujeu"}'
```

### Via Page Admin (Ã  crÃ©er)
```typescript
// Exemple de bouton React
<button onClick={async () => {
  const res = await fetch('/api/admin/ingest', { method: 'POST' })
  const data = await res.json()
  console.log(`ImportÃ©s: ${data.totals.imported}`)
}}>
  Actualiser les Concours
</button>
```

## ğŸ“ Ajouter un Nouveau Scraper

### 1. CrÃ©er le Scraper
```typescript
// lib/scrapers/nouveau_site.ts
import * as cheerio from 'cheerio'
import { RawContest, ScraperConfig } from './types'

async function parseNouveauSite(html: string): Promise<RawContest[]> {
  const $ = cheerio.load(html)
  const contests: RawContest[] = []

  // Votre logique de parsing ici

  return contests
}

export const nouveauSiteScraper: ScraperConfig = {
  name: 'nouveau_site',
  baseUrl: 'https://exemple.com/concours',
  enabled: true,
  rateLimit: 2000,
  userAgent: 'Mozilla/5.0...',
  parser: parseNouveauSite
}
```

### 2. L'Ajouter Ã  l'Index
```typescript
// lib/scrapers/index.ts
import { nouveauSiteScraper } from './nouveau_site'

const SCRAPERS: ScraperConfig[] = [
  lesDemons_DuJeuScraper,
  nouveauSiteScraper, // ğŸ‘ˆ Ajouter ici
]
```

## âš ï¸ Bonnes Pratiques

### Rate Limiting
- **Minimum** : 2 secondes entre chaque requÃªte
- **RecommandÃ©** : 3-5 secondes pour les gros sites
- Respecter le fichier `robots.txt` du site

### User-Agent
Utiliser un User-Agent rÃ©aliste de navigateur rÃ©cent :
```
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36
```

### Gestion d'Erreurs
- âœ… Logs dÃ©taillÃ©s dans la console
- âœ… Continuation mÃªme si un concours Ã©choue
- âœ… Enregistrement des erreurs dans `ingest_logs`

### Protection Anti-Ban
- Rate limiting respectÃ©
- User-Agent rÃ©aliste
- Pas de requÃªtes parallÃ¨les sur le mÃªme domaine
- Gestion des erreurs 403/429

## ğŸ› ï¸ DÃ©pannage

### Le scraper ne trouve rien
1. VÃ©rifier que le site n'a pas changÃ© sa structure
2. Tester les sÃ©lecteurs CSS dans DevTools
3. VÃ©rifier les logs : `console.log` dans le parser

### Erreur 403 Forbidden
- Le site bloque le scraping
- Essayer un User-Agent diffÃ©rent
- Augmenter le rate limit
- Contacter le site pour une API officielle

### Doublons
- Le systÃ¨me vÃ©rifie automatiquement via `lien_source`
- Si doublons persistants, vÃ©rifier la normalisation des URLs

## ğŸ“š RÃ©fÃ©rences

- **Cheerio Docs** : https://cheerio.js.org/
- **Vercel Cron** : https://vercel.com/docs/cron-jobs
- **Cron Syntax** : https://crontab.guru/
- **robots.txt** : https://developers.google.com/search/docs/crawling-indexing/robots/intro
