# Guide de Diagnostic - RÃ©solution des ProblÃ¨mes

## ðŸ”´ ProblÃ¨me 1 : Erreur 406 sur /user_preferences

### SymptÃ´mes
```
Failed to load resource: the server responded with a status of 406 ()
Error: Cannot read properties of null (reading 'email')
```

### Causes Possibles
1. **Row Level Security (RLS)** non configurÃ© correctement dans Supabase
2. L'utilisateur n'a pas les permissions pour lire ses propres prÃ©fÃ©rences

### âœ… Solution : VÃ©rifier les RLS Policies dans Supabase

1. **Aller dans Supabase Dashboard** â†’ Votre projet â†’ Table Editor â†’ `user_preferences`

2. **VÃ©rifier que ces policies existent** :

```sql
-- Policy pour SELECT (lecture)
CREATE POLICY "Users can view their own preferences"
ON public.user_preferences
FOR SELECT
USING (auth.uid() = id);

-- Policy pour INSERT (crÃ©ation)
CREATE POLICY "Users can insert their own preferences"
ON public.user_preferences
FOR INSERT
WITH CHECK (auth.uid() = id);

-- Policy pour UPDATE (mise Ã  jour)
CREATE POLICY "Users can update their own preferences"
ON public.user_preferences
FOR UPDATE
USING (auth.uid() = id)
WITH CHECK (auth.uid() = id);
```

3. **Si les policies n'existent pas, les crÃ©er** :
   - Aller dans "Authentication" â†’ "Policies"
   - SÃ©lectionner la table `user_preferences`
   - Cliquer "New Policy"
   - CrÃ©er les 3 policies ci-dessus

### ðŸ” Test Rapide
AprÃ¨s avoir crÃ©Ã© les policies, dÃ©connectez-vous et reconnectez-vous sur le site.

---

## ðŸ”´ ProblÃ¨me 2 : Le Scraping Ne Fonctionne Pas

### SymptÃ´mes
- Pas de nouveaux concours aprÃ¨s avoir cliquÃ© "Lancer le Scraping"
- La page admin ne montre aucun rÃ©sultat

### Causes Possibles
1. Le site cible (lesdemonsdujeu.com) bloque le scraping (403 Forbidden)
2. La structure HTML du site a changÃ©
3. ProblÃ¨me de connexion Supabase
4. Le scraper n'a jamais Ã©tÃ© exÃ©cutÃ©

### âœ… Diagnostic Ã‰tape par Ã‰tape

#### Ã‰tape 1 : VÃ©rifier les Variables d'Environnement

Dans `.env.local`, vÃ©rifiez que vous avez :
```bash
NEXT_PUBLIC_SUPABASE_URL=https://votre-projet.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=votre_cle_anonyme
```

#### Ã‰tape 2 : Tester le Scraping en Local

```bash
# Terminal 1 - DÃ©marrer le serveur
npm run dev

# Terminal 2 - Tester l'API directement
curl -X POST http://localhost:3000/api/admin/ingest \
  -H "Content-Type: application/json" \
  -v

# Ou via l'interface web
# Ouvrir : http://localhost:3000/admin
# Cliquer sur "ðŸ”„ Lancer le Scraping"
# Ouvrir la console (F12) pour voir les logs
```

#### Ã‰tape 3 : VÃ©rifier les Logs Console

Ouvrez la console du navigateur (F12 â†’ Console) et cherchez :
- âœ… `"Found X contests using selector: ..."` â†’ Le scraper trouve des concours
- âŒ `"No contest elements found"` â†’ Structure HTML diffÃ©rente
- âŒ `"403 Forbidden"` â†’ Le site bloque
- âŒ `"Failed to insert"` â†’ ProblÃ¨me Supabase

#### Ã‰tape 4 : VÃ©rifier dans Supabase

```sql
-- Voir si des concours ont Ã©tÃ© ajoutÃ©s
SELECT COUNT(*), source
FROM concours
GROUP BY source;

-- Voir les derniers concours
SELECT titre, source, created_at
FROM concours
ORDER BY created_at DESC
LIMIT 10;

-- Voir les logs d'ingestion
SELECT *
FROM ingest_logs
ORDER BY started_at DESC
LIMIT 5;
```

### ðŸ› ï¸ Solutions selon le ProblÃ¨me

#### Si Erreur 403 (Site Bloque)
C'est normal, le site `lesdemonsdujeu.com` peut avoir une protection anti-scraping.

**Solutions :**
1. **Ajouter d'autres sources** qui n'ont pas de protection
2. **Contacter le site** pour demander une API officielle
3. **Utiliser un service proxy** (non recommandÃ©)

#### Si "No contest elements found"
La structure HTML du site a changÃ©.

**Solution :**
1. Aller sur https://www.lesdemonsdujeu.com/concours
2. Faire clic droit â†’ "Inspecter"
3. Trouver les sÃ©lecteurs CSS corrects pour les concours
4. Mettre Ã  jour `lib/scrapers/lesdemonsdujeu.ts`

#### Si ProblÃ¨me Supabase
VÃ©rifier les permissions RLS (voir ProblÃ¨me 1 ci-dessus).

---

## ðŸ§ª Test Complet du SystÃ¨me

### Test 1 : Authentification
```bash
1. Aller sur /auth/login
2. Se connecter
3. VÃ©rifier redirection vers /dashboard
âœ… Si Ã§a fonctionne â†’ Auth OK
```

### Test 2 : Settings
```bash
1. Aller sur /settings
2. La page doit se charger sans erreur 406
3. Modifier un paramÃ¨tre et sauvegarder
âœ… Si Ã§a fonctionne â†’ RLS OK
```

### Test 3 : Scraping
```bash
1. Aller sur /admin
2. Cliquer "ðŸ”„ Lancer le Scraping"
3. Ouvrir Console (F12)
4. VÃ©rifier les logs
âœ… Si rÃ©sultats > 0 â†’ Scraping OK
```

### Test 4 : Dashboard
```bash
1. Aller sur /dashboard
2. Voir la liste des concours
3. VÃ©rifier que les concours tests sont lÃ 
âœ… Si concours visibles â†’ Dashboard OK
```

---

## ðŸš€ Solution Alternative : Ajouter des Concours Manuellement

Si le scraping ne fonctionne pas, vous pouvez ajouter des concours via l'API :

```bash
curl -X POST http://localhost:3000/api/concours \
  -H "Content-Type: application/json" \
  -d '{
    "titre": "Concours Test",
    "marque": "Ma Marque",
    "description": "Un super concours Ã  gagner",
    "lien_source": "https://exemple.com/concours-1",
    "type_participation": "direct",
    "categorie_lot": "tech",
    "temps_estime": 5,
    "valeur_estimee": 500,
    "date_fin": "2025-12-31T23:59:59Z"
  }'
```

---

## ðŸ“ž Checklist de Debug

- [ ] Variables d'environnement configurÃ©es
- [ ] RLS Policies crÃ©Ã©es pour `user_preferences`
- [ ] RLS Policies crÃ©Ã©es pour `concours`
- [ ] Compte utilisateur crÃ©Ã© et connectÃ©
- [ ] Page /settings fonctionne sans erreur 406
- [ ] Page /admin accessible
- [ ] Scraping testÃ© (mÃªme si erreur 403)
- [ ] Au moins quelques concours visibles sur /dashboard

---

## ðŸ’¡ Astuce : Mode Debug

Pour voir plus de dÃ©tails, activez les logs dÃ©taillÃ©s :

**Dans `lib/scrapers/index.ts`**, ligne 26 :
```typescript
console.log(`Scraping ${config.name}...`)
console.log(`Fetching: ${config.baseUrl}`) // Ajoutez cette ligne
```

**Dans `lib/scrapers/lesdemonsdujeu.ts`**, ligne 38 :
```typescript
console.log(`Found ${elements.length} contests using selector: ${selector}`)
console.log(`HTML length: ${html.length}`) // Ajoutez avant la boucle
```

---

## ðŸ“š Ressources

- **Supabase RLS** : https://supabase.com/docs/guides/auth/row-level-security
- **Next.js API Routes** : https://nextjs.org/docs/app/building-your-application/routing/route-handlers
- **Cheerio Docs** : https://cheerio.js.org/
- **Debugging Scrapers** : https://github.com/cheeriojs/cheerio/wiki/Cheerio-in-the-DOM
